# -*- coding: utf-8 -*-
"""RNN WIND SPEED.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15ojWCq269de5sULfDrWXGlO-VSnIxv5Q
"""

import tensorflow as tf
import os
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt
import pandas as pd
from tensorflow import keras

# setting parameters for image displays all over
mpl.rcParams['figure.figsize'] = (8, 6)
mpl.rcParams['axes.grid'] = False

# df = pd.read_csv('D:\Datasets\wind_speed.csv')
from google.colab import drive
drive.mount('/content/gdrive')

root_path = 'gdrive/My Drive/BE_Datasets/'

df = pd.read_csv(root_path + '10_Year_WindDataset.csv')
print(df.head())

df.head

Train_split = 1000

tf.random.set_seed = 15

uni_data = df['Wind Speed']
uni_data.index = df['Datetime']
uni_data.head()

uni_data.plot(subplots = True)

uni_data = uni_data.values

#uni_train_min = uni_data[:Train_split].min()
#uni_train_max = uni_data[:Train_split].max()

#uni_data[:Train_split] = (uni_data[:Train_split]-uni_train_min)/(uni_train_max-uni_train_min)

def univariate_data(dataset, start_index, end_index, history_size, target_size):
    data=[]
    labels=[]

    start_index = start_index + history_size
    if end_index is None:
        end_index = len(dataset) - target_size

    for i in range(start_index, end_index):
        indices = range(i-history_size, i)
        # Reshape data from (history_size,) to (history_size, 1)
        data.append(np.reshape(dataset[indices], (history_size, 1)))
        labels.append(dataset[i+target_size])
    return np.array(data), np.array(labels)

univariate_past_history = 20
univariate_future_target = 0

x_train_uni, y_train_uni = univariate_data(uni_data, 0, Train_split,
                                           univariate_past_history,
                                           univariate_future_target)
x_val_uni, y_val_uni = univariate_data(uni_data, Train_split, None,
                                       univariate_past_history,
                                       univariate_future_target)

print ('Single window of past history')
print (x_train_uni[0])
print ('\n Target wind speed to predict')
print (y_train_uni[0])

def create_time_steps(length):
    return list(range(-length, 0))

def show_plot(plot_data, delta, title):
    labels = ['History', 'True Future', 'Model Prediction']
    marker = ['.-', 'rx', 'go']
    time_steps = create_time_steps(plot_data[0].shape[0])
    if delta:
        future = delta
    else:
        future = 0

    plt.title(title)
    for i, x in enumerate(plot_data):
        if i:
            plt.plot(future, plot_data[i], marker[i], markersize=10,
               label=labels[i])
        else:
            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])
    plt.legend()
    plt.xlim([time_steps[0], (future+5)*2])
    plt.xlabel('Time-Step')
    return plt

show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')

def baseline(history):
    return np.mean(history)

show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0,
           'Baseline Prediction Example')

BATCH_SIZE = 64
BUFFER_SIZE = 100

train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))
train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()

val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))
val_univariate = val_univariate.batch(BATCH_SIZE).repeat()

simple_lstm_model = tf.keras.models.Sequential([
    tf.keras.layers.LSTM(64, input_shape=x_train_uni.shape[-2:]),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(1)
])
adam = keras.optimizers.Adam(learning_rate=0.003, beta_1=0.9, beta_2=0.999, amsgrad=False)
simple_lstm_model.compile(optimizer = 'adam', loss='mean_squared_logarithmic_error')

for x, y in val_univariate.take(1):
    print(simple_lstm_model.predict(x).shape)

EVALUATION_INTERVAL = 200
EPOCHS = 10

history = simple_lstm_model.fit(train_univariate, epochs=EPOCHS,
                      steps_per_epoch=EVALUATION_INTERVAL,
                      validation_data=val_univariate, validation_steps=50)

for x, y in val_univariate.take(3):
    plot = show_plot([x[0].numpy(), y[0].numpy(),
                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')
    plot.show()

print(simple_lstm_model.input_shape)

uni_data.shape

prediction_for = uni_data[1000:,]
prediction_for.shape

#prediction_for = prediction_for.reshape(1,298,1)



final_predictions =[None] * 1298
for i in range(1,1278):
    temp_array = uni_data[i:i+20,]
    temp_array = temp_array.reshape(1,20,1)
    ans = simple_lstm_model.predict(temp_array)
    final_predictions[i] = ans

final_predictions = np.asarray(final_predictions)

final_predictions.shape

plt.plot(uni_data, color ='red')
plt.plot(final_predictions)

predicted_wind_speed = simple_lstm_model.predict(val_univariate, steps = 1)

plt.plot(predicted_wind_speed)

